{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMAtbd1DXYwatWaCQCh+u0L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FAKs0Q9WfkeQ","colab_type":"code","colab":{}},"source":["# memory footprint support libraries/code\n","# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","# !pip install gputil\n","# import psutil\n","# import humanize\n","# import os\n","# import GPUtil as GPU\n","# GPUs = GPU.getGPUs()\n","# # XXX: only one GPU on Colab and isn’t guaranteed\n","# gpu = GPUs[0]\n","# def printm():\n","#  process = psutil.Process(os.getpid())\n","#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n","#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","# printm()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QMYdE_HG4Kyg","colab_type":"code","outputId":"dc867858-e3d6-425f-a592-3a8d6129ed42","executionInfo":{"status":"ok","timestamp":1589884721769,"user_tz":-330,"elapsed":8275,"user":{"displayName":"Aman Mehra","photoUrl":"","userId":"11369954633019058515"}},"colab":{"base_uri":"https://localhost:8080/","height":302}},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue May 19 10:38:36 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KoicoLsuhFNV","colab_type":"code","outputId":"83e637d0-5fd3-4cdd-ee22-1f6658477ec8","executionInfo":{"status":"ok","timestamp":1589884813734,"user_tz":-330,"elapsed":26651,"user":{"displayName":"Aman Mehra","photoUrl":"","userId":"11369954633019058515"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o3LmRbWihIqU","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torchvision import transforms\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader, random_split\n","from torchsummary import summary\n","from torch.utils.tensorboard import SummaryWriter\n","import torchvision\n","import scipy.ndimage\n","from skimage.metrics import structural_similarity as ssim\n","from skimage.color import rgb2ycbcr\n","from scipy import misc\n","from PIL import Image\n","import numpy as np\n","import cv2, os, math, random, json, time, pickle, imageio \n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from tqdm import tqdm\n","from multiprocessing.dummy import Pool as ThreadPool\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j4H95nSQhInc","colab_type":"code","outputId":"b3cffbbf-68b9-4716-a2d5-ef797c178b2b","executionInfo":{"status":"ok","timestamp":1589885046753,"user_tz":-330,"elapsed":5118,"user":{"displayName":"Aman Mehra","photoUrl":"","userId":"11369954633019058515"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["cuda = torch.device('cuda:0')  # CUDA GPU 0\n","print(torch.cuda.get_device_name(cuda))\n","print(torch.__version__)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Tesla P100-PCIE-16GB\n","1.5.0+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l1y_aIzwhIkw","colab_type":"code","colab":{}},"source":["data_root = \"/content/drive/My Drive/SML Project/Dataset/\"\n","data_paths = {\"DIV2K\": {\"train\":\n","                      {\"HR\":\"DIV2K/DIV2K_train_HR/\",\n","                      \"LR_BI\": { \"X2\":\"DIV2K/DIV2K_train_LR_bicubic/X2/\", \"X3\":\"DIV2K/DIV2K_train_LR_bicubic/X3/\", \"X4\":\"DIV2K/DIV2K_train_LR_bicubic/X4/\" },\n","                      \"LR_UN\": { \"X2\":\"DIV2K/DIV2K_train_LR_unknown/X2/\", \"X3\":\"DIV2K/DIV2K_train_LR_unknown/X3/\", \"X4\":\"DIV2K/DIV2K_train_LR_unknown/X4/\" }\n","                      } ,\n","                        \"val\":\n","                      {\"HR\":\"DIV2K/DIV2K_valid_HR/\",\n","                      \"LR_BI\": { \"X2\":\"DIV2K/DIV2K_valid_LR_bicubic/X2/\", \"X3\":\"DIV2K/DIV2K_valid_LR_bicubic/X3/\", \"X4\":\"DIV2K/DIV2K_valid_LR_bicubic/X4/\" },\n","                      \"LR_UN\": { \"X2\":\"DIV2K/DIV2K_valid_LR_unknown/X2/\", \"X3\":\"DIV2K/DIV2K_valid_LR_unknown/X3/\", \"X4\":\"DIV2K/DIV2K_valid_LR_unknown/X4/\" }\n","                      } },\n","              \"Flickr2K\":{\"train\":\n","                         {  \"HR\":\"Flickr2K/Flickr2K_HR/\",\n","                             \"LR_BI\":  { \"X2\":\"Flickr2K/Flickr2K_LR_bicubic/X2/\", \"X3\":\"Flickr2K/Flickr2K_LR_bicubic/X3/\", \"X4\":\"Flickr2K/Flickr2K_LR_bicubic/X4/\" },\n","                             \"LR_UN\":  { \"X2\":\"Flickr2K/Flickr2K_LR_unknown/X2/\", \"X3\":\"Flickr2K/Flickr2K_LR_unknown/X3/\", \"X4\":\"Flickr2K/Flickr2K_LR_unknown/X4/\" }\n","                         } ,\n","                          \"val\":\n","                        {\"HR\":\"DIV2K/DIV2K_valid_HR/\",\n","                        \"LR_BI\": { \"X2\":\"DIV2K/DIV2K_valid_LR_bicubic/X2/\", \"X3\":\"DIV2K/DIV2K_valid_LR_bicubic/X3/\", \"X4\":\"DIV2K/DIV2K_valid_LR_bicubic/X4/\" },\n","                        \"LR_UN\": { \"X2\":\"DIV2K/DIV2K_valid_LR_unknown/X2/\", \"X3\":\"DIV2K/DIV2K_valid_LR_unknown/X3/\", \"X4\":\"DIV2K/DIV2K_valid_LR_unknown/X4/\" }\n","                      } },\n","                \"Set5\":{\"HR\":  {\"X2\":\"Set5/HR/x2/\", \"X3\":\"Set5/HR/x3/\", \"X4\":\"Set5/HR/x4/\" },\n","                        \"LR_BI\": { \"X2\":\"Set5/LR/LR_BI/x2/\", \"X3\":\"Set5/LR/LR_BI/x3/\", \"X4\":\"Set5/LR/LR_BI/x4/\" },\n","                      },\n","                \"Set14\":{\"HR\":  {\"X2\":\"Set14/HR/X2/\", \"X3\":\"Set14/HR/X3/\", \"X4\":\"Set14/HR/X4/\" },\n","                        \"LR_BI\": { \"X2\":\"Set14/LR/LR_BI/X2/\", \"X3\":\"Set14/LR/LR_BI/X3/\", \"X4\":\"Set14/LR/LR_BI/X4/\" },\n","                      },\n","              }\n","\n","kernel_attrs = {\"2\":(6,2,2),\"3\":(7,3,2),\"4\":(8,4,2)}\n","patch_sizes = {\"2\":60,\"3\":50,\"4\":40}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rAtBSpPYNPZV","colab_type":"code","colab":{}},"source":["class AutoAugment:\n","    def __init__(self,dataset = 'DIV2K', split = 'train', downsampling = \"LR_BI\", scale = 4):\n","        self.split = split\n","        self.dataset = dataset\n","        self.downsampling = downsampling\n","        self.scale = scale\n","        self.zooms = [0.8,0.7,0.6,0.5]\n","\n","        self.hr,self.lr = self._get_img_list()\n","\n","    def _aug(self,img,size,ctr,path):\n","        h,w,_ = img.shape\n","        img = np.array(Image.fromarray(img).resize((int(w*size),int(h*size)),resample=Image.BICUBIC))\n","        h,w,_ = img.shape\n","        h = h - np.mod(h, self.scale)\n","        w = w - np.mod(w, self.scale)\n","        img = img[0:h, 0:w, :]\n","\n","        img_flip = np.array(Image.fromarray(img).rotate(180,resample=Image.BICUBIC))\n","        lr = np.array(Image.fromarray(img).resize((int(w/int(self.scale)),int(h/self.scale)),resample=Image.BICUBIC))\n","        lr_flip = np.array(Image.fromarray(img_flip).resize((int(w/self.scale),int(h/self.scale)),resample=Image.BICUBIC)) \n","\n","        imageio.imwrite(path.split('.')[0]+\"_\"+str(ctr)+\".png\" , img)\n","        imageio.imwrite(path.split('.')[0]+\"_\"+str(ctr+1)+\".png\" , img_flip)\n","        imageio.imwrite(data_root+data_paths[self.dataset][self.split][self.downsampling][\"X\"+str(self.scale)]+path.split('/')[-1].split('.')[0]+\"x\"+str(self.scale)+\"_\"+str(ctr)+\".png\", lr)\n","        imageio.imwrite(data_root+data_paths[self.dataset][self.split][self.downsampling][\"X\"+str(self.scale)]+path.split('/')[-1].split('.')[0]+\"x\"+str(self.scale)+\"_\"+str(ctr+1)+\".png\", lr_flip)\n","\n","    def _aug_img(self,path):\n","        print(\"Augmenting\",path.split('/')[-1].split('.')[0],\"/ 800\")\n","        img = imageio.imread(path)\n","        ctr = 9 #\n","        for sz in self.zooms:\n","            self._aug(img,sz,ctr,path)\n","            ctr+=2\n","        h,w,_ = img.shape\n","        h = h - np.mod(h, self.scale)\n","        w = w - np.mod(w, self.scale)\n","        img = img[0:h, 0:w, :]\n","        img_flip = np.array(Image.fromarray(img).rotate(180,resample=Image.BICUBIC))\n","        imageio.imwrite(path.split('.')[0]+\"_\"+str(ctr)+\".png\" , img_flip)\n","        lr_flip = np.array(Image.fromarray(img_flip).resize((int(w/self.scale),int(h/self.scale)),resample=Image.BICUBIC)) \n","        imageio.imwrite(data_root+data_paths[self.dataset][self.split][self.downsampling][\"X\"+str(self.scale)]+path.split('/')[-1].split('.')[0]+\"x\"+str(self.scale)+\"_\"+str(ctr)+\".png\", lr_flip)     \n","\n","    def autoaugment(self):\n","        if len(self.hr)!=800:\n","            print(len(self.hr))\n","            return\n","        # pool = ThreadPool()\n","        # pool.map(self._aug_img, self.hr)\n","        # pool.close()\n","        # pool.join()\n","        for pth in self.hr:\n","            if \"_\" not in pth.split(\"/\")[-1]:\n","                self._aug_img(pth)\n","            \n","\n","    def cleanup(self):\n","        if len(self.hr) == 800:\n","            print(\"Nothing to cleanup\")\n","            return\n","        for pth in self.hr:\n","            if \"_\" in pth.split(\"/\")[-1]:\n","                os.remove(pth)\n","                \n","    def _get_img_list(self):\n","        hr_imgs = [data_root+data_paths[self.dataset][self.split][\"HR\"]+img for img in os.listdir(data_root+data_paths[self.dataset][self.split][\"HR\"])]\n","        lr_imgs = [data_root+data_paths[self.dataset][self.split][self.downsampling][\"X\"+str(self.scale)]+img for img in os.listdir(data_root+data_paths[self.dataset][self.split][self.downsampling][\"X\"+str(self.scale)])] \n","        \n","        hr_imgs.sort()\n","        lr_imgs.sort()\n","        return hr_imgs,lr_imgs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jz3GCOXYTapk","colab_type":"code","colab":{}},"source":["# aug = AutoAugment()\n","# aug.autoaugment()\n","# aug.cleanup()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e5SyE8-RhIic","colab_type":"code","colab":{}},"source":["class DataSet(Dataset):\n","    \n","    def __init__(self,dataset = \"train\", split = 'train', downsampling = \"LR_BI\", scale = \"X4\", no_aug = False):\n","        \n","        self.split = split\n","        self.dataset = [\"DIV2K\"] if dataset == \"train\" else [dataset] # ,\"Flickr2K\"\n","        self.downsampling = downsampling\n","        self.scale = scale\n","        self.no_aug = no_aug\n","\n","        random.seed(1)\n","        \n","        if self.split == 'train':\n","            self.start_percent = 0\n","            self.end_percent = 0.8\n","        elif self.split == 'val':\n","            self.start_percent = 0.8\n","            self.end_percent = 0.9\n","        elif self.split == 'test':\n","            self.start_percent = 0.9\n","            self.end_percent = 1\n","            \n","            \n","        self.hr,self.lr = self._get_img_list() \n","        self.hr,self.lr = self.hr,self.lr\n","\n","        self.transforms = transforms.Compose([ transforms.ToPILImage(),  \n","                                               transforms.ToTensor()])                   \n","    def __len__(self):\n","        return len(self.hr)\n","    \n","    def __getitem__(self,idx):\n","        lr, hr = self._get_input_tensor(idx)\n","        return lr, hr ,self.hr[idx]\n","\n","    def _augment(self,lr,hr, prob=0.5):\n","        augmented_lr = lr\n","        augmented_hr = hr\n","        x = random.uniform(0,1)\n","        if x < prob:\n","            augmented_lr = augmented_lr.transpose(1,0,2)\n","            augmented_hr = augmented_hr.transpose(1,0,2)\n","        if x < prob:\n","            augmented_lr = augmented_lr.transpose(1,0,2)[::-1,::-1,:]\n","            augmented_hr = augmented_hr.transpose(1,0,2)[::-1,::-1,:]\n","        if x < prob:\n","            augmented_lr = np.fliplr(augmented_lr)\n","            augmented_hr = np.fliplr(augmented_hr)\n","        return augmented_lr, augmented_hr\n","\n","    def _extract_patch(self,lr,hr):\n","        lh,lw,_ = lr.shape\n","        hh,hw,_ = hr.shape\n","\n","        scale = int(self.scale[-1])\n","        patch = patch_sizes[str(scale)]\n","\n","        while True:\n","          ld = int(min(lh,lw))\n","          lhp = np.random.randint(10,ld-patch-10)\n","          lwp = np.random.randint(10,ld-patch-10)\n","\n","          lr_crop = lr[lhp:(lhp+patch),lwp:(lwp+patch),:]\n","          hr_crop = hr[lhp*scale:(lhp+patch)*scale,lwp*scale:(lwp+patch)*scale,:]\n","\n","          try:\n","            assert hr_crop.shape[0]==hr_crop.shape[1], hr_crop.shape\n","            break\n","          except:\n","            lh,lw = lw,lh\n","            continue\n","\n","        return lr_crop, hr_crop\n","\n","    def _get_input_tensor(self,idx):    \n","        # st = time.time()\n","        lr_im = cv2.imread(self.lr[idx],1)\n","        hr_im = cv2.imread(self.hr[idx],1) \n","        lr_im = cv2.cvtColor(lr_im,cv2.COLOR_BGR2RGB)\n","        hr_im = cv2.cvtColor(hr_im,cv2.COLOR_BGR2RGB)\n","        if self.split == \"train\":\n","          lr_im,hr_im = self._extract_patch(lr_im,hr_im)\n","        # print(lr_im.shape,hr_im.shape)\n","        # lr_im, hr_im = self._augment(lr_im,hr_im,0.5)\n","        lr_im = self.transforms(lr_im)\n","        hr_im = self.transforms(hr_im)\n","        # print(time.time()-st)\n","        return lr_im, hr_im\n","  \n","    def _get_img_list(self):\n","\n","        hr, lr = [], []\n","        for dataset in self.dataset:\n","            if self.split==\"val\":\n","                hr_imgs = [data_root+data_paths[dataset][\"HR\"][self.scale]+img for img in os.listdir(data_root+data_paths[dataset][\"HR\"][self.scale])]\n","                lr_imgs = [data_root+data_paths[dataset][\"LR_BI\"][self.scale]+img for img in os.listdir(data_root+data_paths[dataset][\"LR_BI\"][self.scale])]\n","            else:\n","                hr_imgs = [data_root+data_paths[dataset][self.split][\"HR\"]+img for img in os.listdir(data_root+data_paths[dataset][self.split][\"HR\"])  if  not (self.no_aug and \"_\" in img) ]\n","                lr_imgs = [data_root+data_paths[dataset][self.split][self.downsampling][self.scale]+img for img in os.listdir(data_root+data_paths[dataset][self.split][self.downsampling][self.scale]) if  not (self.no_aug and \"_\" in img) ] \n","                \n","            hr_imgs.sort()\n","            lr_imgs.sort()\n","            \n","            if dataset == \"Flickr2K\":\n","                hr_imgs = hr_imgs[int(self.start_percent*len(hr_imgs)):int(self.end_percent*len(hr_imgs))]\n","                lr_imgs = lr_imgs[int(self.start_percent*len(lr_imgs)):int(self.end_percent*len(lr_imgs))]\n","\n","            hr.extend(hr_imgs)\n","            lr.extend(lr_imgs)\n","\n","        return hr, lr\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pGH3q4XTNauw","colab_type":"code","colab":{}},"source":["# d = DataSet('train','train',scale=\"X3\",no_aug=True)\n","# for i in range(50):\n","#   print(d[i][0].shape,d[i][1].shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fvbpHAgUOq8y","colab_type":"code","colab":{}},"source":["class MeanShift(nn.Conv2d):\n","    def __init__(self, rgb_mean, rgb_std, sign=-1):\n","        super(MeanShift, self).__init__(3, 3, kernel_size=1)\n","        std = torch.Tensor(rgb_std)\n","        self.weight.data = torch.eye(3).view(3, 3, 1, 1)\n","        self.weight.data.div_(std.view(3, 1, 1, 1))\n","        self.bias.data = sign * 255. * torch.Tensor(rgb_mean)\n","        self.bias.data.div_(std)\n","        for p in self.parameters():\n","            p.requires_grad = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DPjg4IQhnkEq","colab_type":"code","colab":{}},"source":["class S_E_Block(nn.Module):\n","    def __init__(self, in_ch, r):\n","        super(S_E_Block, self).__init__()\n","        self.linear_1 = nn.Linear(in_ch, in_ch//r)\n","        self.linear_2 = nn.Linear(in_ch//r, in_ch)\n","        self.sigmoid = nn.Sigmoid()\n","\n","        for m in self.modules():\n","          if isinstance(m, nn.Linear):\n","              nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n","              if m.bias is not None:\n","                  m.bias.data.zero_()\n","\n","    def forward(self, ip):\n","        x = ip\n","        x = x.view((x.shape[0],x.shape[1],-1)).mean(-1)\n","        x = F.relu(self.linear_1(x), inplace=True)\n","        x = self.linear_2(x)\n","        x = x.unsqueeze(-1).unsqueeze(-1)\n","        x = self.sigmoid(x)\n","        x = ip * x\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Ihitt_33lEC","colab_type":"code","colab":{}},"source":["\n","class LRFeatureExtractor(nn.Module):\n","\n","    def __init__(self,in_channels = 3, num_filters = 32):\n","        super(LRFeatureExtractor, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, num_filters*4, 3 , stride=1, padding=1, dilation=1, bias=True)\n","        self.activation = nn.PReLU(num_parameters=1, init=0.2)\n","        self.conv2 = nn.Conv2d(num_filters*4, num_filters, 1 , stride=1, padding=0, dilation=1, bias=True)\n","        \n","        for m in self.modules():\n","          if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n","              nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n","              if m.bias is not None:\n","                  m.bias.data.zero_()\n","\n","\n","    def forward(self,x):\n","      x = self.activation(self.conv1(x))\n","      x = self.activation(self.conv2(x))\n","      return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WwP-Gl_cLhkh","colab_type":"code","colab":{}},"source":["class ProjectionBlock(nn.Module):\n","\n","    def __init__(self, block_num, num_filters, kernel_size, stride, padding):\n","        super(ProjectionBlock, self).__init__()\n","        self.block_num = block_num\n","        if block_num > 1:\n","            self.compress_deconv = nn.Conv2d(block_num*num_filters, num_filters, 1)\n","            self.compress_conv = nn.Conv2d(block_num*num_filters, num_filters, 1)\n","\n","        self.deconv = nn.ConvTranspose2d(num_filters, num_filters, kernel_size, stride = stride, padding = padding)\n","        self.conv = nn.Conv2d(num_filters, num_filters, kernel_size, stride = stride, padding = padding)\n","        self.activation = nn.PReLU(num_parameters=1, init=0.2)\n","\n","        self.se1 = S_E_Block(in_ch=num_filters, r=16)\n","        self.se2 = S_E_Block(in_ch=num_filters, r=16)\n","\n","        for m in self.modules():\n","          if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n","              nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n","              if m.bias is not None:\n","                  m.bias.data.zero_()\n","\n","    def forward(self,lr,hr):\n","        if self.block_num > 1:\n","            h = self.activation(self.se1(self.deconv(self.activation(self.compress_deconv(lr)))))\n","            h = torch.cat((h,hr), dim=1)\n","            l = self.activation(self.se2(self.conv(self.activation(self.compress_conv(h)))))\n","        else:\n","            h = self.activation(self.se1(self.deconv(lr)))\n","            l = self.activation(self.se2(self.conv(h)))\n","        l = torch.cat((l,lr), dim=1)\n","        return l, h"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UpatQJB47XLK","colab_type":"code","colab":{}},"source":["class FeedbackBlock(nn.Module):\n","\n","    def  __init__(self, num_blocks, num_filters, kernel_size, stride, padding):\n","        super(FeedbackBlock, self).__init__()\n","        self.num_filters = num_filters\n","        self.num_blocks = num_blocks\n","\n","        self.lr_in_compress = nn.Conv2d(num_filters*2, num_filters, 1 , stride=1, padding=0, dilation=1, bias=True)\n","        self.blocks = [ProjectionBlock(1,num_filters, kernel_size, stride, padding)]\n","        for blk_num in range(2,num_blocks+1):\n","            self.blocks.append(ProjectionBlock(blk_num,num_filters, kernel_size, stride, padding))\n","        self.lr_out_compress = nn.Conv2d(num_filters*num_blocks, num_filters, 1 , stride=1, padding=0, dilation=1, bias=True)\n","        self.activation = nn.PReLU(num_parameters=1, init=0.2)\n","\n","        for m in self.modules():\n","          if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n","              nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n","              if m.bias is not None:\n","                  m.bias.data.zero_()\n","\n","        for blk in self.blocks:\n","          blk.cuda()\n","          \n","    def forward(self,x):\n","        lr = self.activation(self.lr_in_compress(x))\n","        lr, hr = self.blocks[0](lr,0)\n","        del x\n","        for i in range(1,self.num_blocks):\n","            lr, hr = self.blocks[i](lr, hr) \n","        del hr\n","        lr = lr[:,self.num_filters:,:,:]\n","        lr = self.activation(self.lr_out_compress(lr))\n","        return lr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uI4Hi5w9hIgI","colab_type":"code","colab":{}},"source":["class SRFBN_Orig(nn.Module):\n","    def __init__(self, in_channels=3, out_channels=3, num_features=32, num_steps=4, num_groups=6, upscale_factor=4, act_type = 'prelu', norm_type = None):\n","        super(SRFBN_Orig, self).__init__()\n","\n","        kernel_size, stride, padding = kernel_attrs[str(upscale_factor)]\n","\n","        self.num_steps = num_steps\n","        self.num_features = num_features\n","        self.upscale_factor = upscale_factor\n","\n","        rgb_mean = (0.4488, 0.4371, 0.4040)\n","        rgb_std = (1.0, 1.0, 1.0)\n","        self.sub_mean = MeanShift(rgb_mean, rgb_std)\n","\n","        # LR feature extraction block\n","        self.lrfb = LRFeatureExtractor(3,num_features)\n","\n","        # basic block\n","        self.block = FeedbackBlock(num_groups, num_features, kernel_size, stride, padding)\n","\n","        self.rb = nn.Sequential(nn.ConvTranspose2d(num_features, num_features, kernel_size, stride = stride, padding = padding),\n","                              S_E_Block(in_ch=num_features, r=16),\n","                              nn.PReLU(num_parameters=1, init=0.2),\n","                              nn.Conv2d(num_features,out_channels,3,padding=1,bias = True))\n"," \n","        self.add_mean = MeanShift(rgb_mean, rgb_std, 1)\n","\n","        for m in self.modules():\n","          classname = m.__class__.__name__\n","          if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n","              if classname != \"MeanShift\":\n","                  nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n","                  if m.bias is not None:\n","                      m.bias.data.zero_()\n","\n","    def forward(self, x):\n","        x = self.sub_mean(x)\n","        inter_res = nn.functional.interpolate(x, scale_factor=self.upscale_factor, mode='bilinear', align_corners=False)\n","        x = self.lrfb(x)\n","\n","        f_in = torch.cat((x,x), dim=1)\n","        outs = []\n","        for it in range(self.num_steps):\n","            f_out = self.block(f_in)\n","            f_in = torch.cat((f_in[:,self.num_features:,:,:],f_out), dim=1)\n","            outs.append(self.add_mean(torch.add(self.rb(f_out),inter_res)))\n","\n","        return outs # return output of every timesteps\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMyLHDnqhId0","colab_type":"code","colab":{}},"source":["class Trainer:\n","\n","  def __init__(self, batch_size = 16, scale = 4, num_filters = 32, num_blocks = 6, num_iters = 4, skip_train = False):\n","      self.batch_size = batch_size\n","      self.scale = scale\n","      self.num_filters = num_filters\n","      self.num_blocks = num_blocks\n","      self.num_iters = num_iters\n","      self.skip_train = skip_train\n","      self._create_dataloaders()\n","      self._create_model()\n","      self._create_peripherals()\n","\n","  def _create_dataloaders(self):\n","      if not self.skip_train:\n","        self.trainset = DataSet(dataset = 'train', split = 'train', downsampling = \"LR_BI\", scale = \"X\"+str(self.scale), no_aug=True)\n","        self.trainloader = DataLoader(self.trainset, batch_size=self.batch_size, shuffle=True, drop_last=False, num_workers=4)\n","      # self.valset = DataSet(dataset = 'Set5', split = 'val', downsampling = \"LR_BI\", scale = \"X\"+str(self.scale))\n","      # self.valloader = DataLoader(self.valset, batch_size=1, shuffle=False, drop_last=False)\n","      self.valset = DataSet(dataset = 'Set14', split = 'val', downsampling = \"LR_BI\", scale = \"X\"+str(self.scale))\n","      self.valloader = DataLoader(self.valset, batch_size=1, shuffle=False, drop_last=False)\n","\n","  def _create_model(self):\n","      # self.model = SRFBN(num_blocks=self.num_blocks, num_iters=self.num_iters, scale=self.scale, num_filters = self.num_filters)\n","      self.model = SRFBN_Orig(upscale_factor = self.scale)\n","\n","  def _create_peripherals(self):\n","      self.last_batch_loss = float('inf')\n","      self.best_ssim = -1\n","      self.start_epoch = 1\n","\n","  def load_checkpoint(self):\n","      self.start_epoch = 1\n","      ckpt_path = \"/content/drive/My Drive/SML Project/checkpoints/SRFBN_SE_\"+str(self.scale)+\"_best\"+\".pth\"   # \n","      if os.path.exists(ckpt_path):\n","          print(\"Loading from checkpoint...\")\n","          checkpoint = torch.load(ckpt_path)\n","          self.model.load_state_dict(checkpoint['model'])\n","          self.optimizer.load_state_dict(checkpoint['optimizer'])\n","          self.scheduler.load_state_dict(checkpoint['scheduler'])\n","          self.start_epoch = checkpoint['epoch']+1\n","          self.best_ssim = checkpoint['ssim']\n","          self.record = checkpoint['record']\n","\n","  def save_checkpoint(self,epoch,best = False):\n","      print(\"Saving checkpoint...\")\n","      torch.save({\n","          'epoch': epoch,\n","          'model': self.model.state_dict(),\n","          'optimizer': self.optimizer.state_dict(),\n","          'scheduler': self.scheduler.state_dict(),\n","          'ssim': self.best_ssim,\n","          'record': self.record\n","          }, \"/content/drive/My Drive/SML Project/checkpoints/SRFBN_SE_\"+str(self.scale)+\".pth\")\n","      if best:\n","          print(\"Saving best checkpoint...\")\n","          torch.save({\n","              'epoch': epoch,\n","              'model': self.model.state_dict(),\n","              'optimizer': self.optimizer.state_dict(),\n","              'scheduler': self.scheduler.state_dict(),\n","              'ssim': self.best_ssim,\n","              'record': self.record\n","              }, \"/content/drive/My Drive/SML Project/checkpoints/SRFBN_SE_\"+str(self.scale)+\"_best\"+\".pth\")\n","          \n","  def logger(self):\n","      plt.plot(self.record['validation_losses'])\n","      plt.plot(self.record['epoch_losses'])\n","      plt.suptitle('Losses')\n","      plt.savefig(\"/content/drive/My Drive/SML Project/plots/Training_SR/Log/SRFBN_SE_\"+str(self.scale)+\"_loss.png\",dpi=1200)\n","      plt.close()\n","      plt.plot(self.record['validation_psnr'])\n","      plt.suptitle('PSNR')\n","      plt.savefig(\"/content/drive/My Drive/SML Project/plots/Training_SR/Log/SRFBN_SE_\"+str(self.scale)+\"_psnr.png\",dpi=1200)\n","      plt.close()\n","      plt.plot(self.record['validation_ssim'])\n","      plt.suptitle('SSIM')\n","      plt.savefig(\"/content/drive/My Drive/SML Project/plots/Training_SR/Log/SRFBN_SE_\"+str(self.scale)+\"_ssim.png\",dpi=1200)\n","      plt.close()\n","      \n","  def PSNR(self,img1, img2, max_val=225):\n","      # assert img1.shape == img2.shape\n","      # if len(img1.shape) >= 3:\n","      #     img1 = rgb2ycbcr(img1)\n","      #     img2 = rgb2ycbcr(img2)\n","      mse = img1 - img2\n","      mse = np.mean(mse ** 2)\n","      psnr = 10 * math.log((max_val ** 2 )/ mse, 10)\n","      return psnr\n","\n","  def SSIM(self,img1, img2):\n","      return ssim(img1, img2, multichannel=False) # True\n","\n","  def get_metrics(self, sr_batch, hr_batch):\n","      ssim_s = []\n","      psnr_s = []\n","      for ind in range(sr_batch.shape[0]):\n","          sr, hr = imgYCC = cv2.cvtColor(sr_batch[ind,:,:,:], cv2.COLOR_RGB2YCR_CB), cv2.cvtColor(hr_batch[ind,:,:,:], cv2.COLOR_RGB2YCR_CB)\n","          ssim_s.append(self.SSIM(sr[:,:,0],hr[:,:,0]))\n","          psnr_s.append(self.PSNR(sr[:,:,0],hr[:,:,0]))\n","      ssim_s = sum(ssim_s)/len(ssim_s)\n","      psnr_s = sum(psnr_s)/len(psnr_s)\n","      return ssim_s , psnr_s\n","\n","  def train(self):\n","      os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","\n","      self.record={'epoch_losses':[],'validation_losses':[],'validation_psnr':[],'validation_ssim':[]}\n","  \n","      pix_loss = nn.L1Loss()\n","      pix_loss = pix_loss.cuda()\n","      torch.cuda.empty_cache()\n","      self.model = self.model.to(cuda)\n","      \n","      self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001 , weight_decay=0)\n","      self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer,[70,140,200,250],0.5)          \n","      self.load_checkpoint()\n","      print(\"Starting from epoch = \",self.start_epoch)\n","\n","      for epoch in range(self.start_epoch,self.start_epoch+1000):\n","\n","          if not self.skip_train:\n","\n","            self.model.train()         \n","            batch_losses = []\n","            \n","            for i, batch in enumerate(self.trainloader):\n","                self.optimizer.zero_grad()\n","                \n","                lr,hr = batch[0],batch[1]  \n","                lr = lr.to(cuda)\n","                hr = hr.to(cuda)   \n","                \n","                sr_outs = self.model.forward(lr) \n","                out_loss = 0\n","                for sr in sr_outs:\n","                  # print(sr.detach().cpu().numpy().shape,hr.detach().cpu().numpy().shape)\n","                  out_loss += pix_loss(sr,hr)\n","                \n","                out_loss.backward()\n","\n","                if (i+1)%5 == 0:\n","                    print(\"Iterations completed = \",i,\"/\",len(self.trainloader))\n","\n","                if out_loss < 3* self.last_batch_loss:\n","                    self.optimizer.step()\n","                    self.last_batch_loss = out_loss\n","                \n","                batch_losses.append(out_loss.item())\n","                    \n","            self.record['epoch_losses'].append(sum(batch_losses)/len(batch_losses))\n","            print(\"After epoch \",epoch,\" Training Loss = \",self.record['epoch_losses'][-1])\n","\n","          self.optimizer.zero_grad()\n","          self.model.eval()\n","          batch_losses = []\n","          batch_psnr = []\n","          batch_ssim = []\n","\n","          for i, batch in enumerate(self.valloader):\n","              lr,hr = batch[0],batch[1]  \n","              lr = lr.to(cuda)\n","              hr = hr.to(cuda)   \n","              \n","              sr_outs = self.model.forward(lr)\n","              out_loss = 0\n","              for sr in sr_outs:\n","                out_loss += pix_loss(sr,hr)\n","              \n","              out_loss.backward()\n","              batch_losses.append(out_loss.item())\n","              sr_ip, hr_ip = sr_outs[-1].detach().cpu().permute(0, 2, 3, 1).numpy(), hr.detach().cpu().permute(0, 2, 3, 1).numpy()\n","              ssim, psnr = self.get_metrics(sr_ip, hr_ip)\n","              batch_psnr.append(psnr)\n","              batch_ssim.append(ssim)\n","              \n","              # plt.imshow(np.hstack((sr_ip[0,:,:,:],hr_ip[0,:,:,:])))\n","              # plt.savefig(\"/content/drive/My Drive/SML Project/plots/Training_SR/X\"+str(self.scale)+\"-SE/\"+str(epoch)+\"_\"+str(i)+\".png\",dpi=1200)\n","              # plt.close()\n","             \n","          \n","          self.record['validation_psnr'].append(sum(batch_psnr)/len(batch_psnr))\n","          self.record['validation_ssim'].append(sum(batch_ssim)/len(batch_ssim))\n","          self.record['validation_losses'].append(sum(batch_losses)/len(batch_losses))\n","\n","          print(\"After epoch \",epoch,\" Val Loss = \",self.record['validation_losses'][-1],\" Val SSIM = \",self.record['validation_ssim'][-1],\" Val PSNR = \",self.record['validation_psnr'][-1])\n","          self.scheduler.step()\n","          break\n","          last_best = self.best_ssim\n","          if self.record['validation_ssim'][-1]>self.best_ssim:\n","              self.best_ssim = self.record['validation_ssim'][-1]\n","          self.save_checkpoint(epoch,self.record['validation_ssim'][-1]>last_best)\n","\n","          self.logger()\n","          "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dtQ77pkUhIbG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"525a46a6-f762-4874-8009-3d6751e0ce56","executionInfo":{"status":"error","timestamp":1589885779716,"user_tz":-330,"elapsed":61026,"user":{"displayName":"Aman Mehra","photoUrl":"","userId":"11369954633019058515"}}},"source":["trainer = Trainer(batch_size=16,scale=3,skip_train=False) # batch_size = 30 for scale 2"],"execution_count":29,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-987ad4469e4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_size = 30 for scale 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-5c3e04ff6cdd>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_size, scale, num_filters, num_blocks, num_iters, skip_train)\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskip_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_peripherals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-5c3e04ff6cdd>\u001b[0m in \u001b[0;36m_create_dataloaders\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LR_BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"X\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;31m# self.valset = DataSet(dataset = 'Set5', split = 'val', downsampling = \"LR_BI\", scale = \"X\"+str(self.scale))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-9b292f41b849>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, split, downsampling, scale, no_aug)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_img_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-9b292f41b849>\u001b[0m in \u001b[0;36m_get_img_list\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mlr_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"LR_BI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"LR_BI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mhr_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HR\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HR\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mif\u001b[0m  \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_aug\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0mlr_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsampling\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsampling\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m  \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_aug\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/content/drive/My Drive/SML Project/Dataset/DIV2K/DIV2K_train_HR/'"]}]},{"cell_type":"code","metadata":{"id":"Ffs3_mKkhIU4","colab_type":"code","colab":{}},"source":["trainer.train() "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"drIGJY6b0xF-","colab_type":"code","colab":{}},"source":["import numpy as np\n","import cv2\n","import random\n","\n","\n","def augment(image, ratio_noraml_anticlock_clock_fliphr):\n","    ratio_noraml_anticlock_clock_fliphr = ratio_noraml_anticlock_clock_fliphr/np.sum(ratio_noraml_anticlock_clock_fliphr)\n","    ratio_noraml_anticlock_clock_fliphr = [sum(ratio_noraml_anticlock_clock_fliphr[:x]) for x in range(1, len(ratio_noraml_anticlock_clock_fliphr)+1)]\n","    augmented_image = None\n","    x = random.uniform(0,1)\n","    if x < ratio_noraml_anticlock_clock_fliphr[0]:\n","        augmented_image = image\n","    elif x < ratio_noraml_anticlock_clock_fliphr[1]:\n","        augmented_image = np.rot90(image, 1)\n","    elif x < ratio_noraml_anticlock_clock_fliphr[2]:\n","        augmented_image = np.rot90(image, 3)\n","    elif x < ratio_noraml_anticlock_clock_fliphr[3]:\n","        augmented_image = np.fliplr(image)\n","    return augmented_image\n","\n","\n","def BD(image, size):\n","    \"\"\"\n","    Gaussian blur with kernel 7*7 with stddev 1.6 followed by  down sampling with BICUBIC interpolation\n","    :param image:\n","    :return:\n","    \"\"\"\n","    blurred_image = cv2.GaussianBlur(image, (7, 7), 1.6)\n","    HR_img =cv2.resize(blurred_image, (int(blurred_image.shape[1]*size/100), int(blurred_image.shape[0]*size/100)), interpolation=cv2.INTER_CUBIC)\n","    return HR_img\n","\n","\n","def DN(image, size, noise_scale):\n","    \"\"\"\n","    Dlown sampled by param size by BICUBIC interpolation and then Gausssian noise of given noise_scale is applied\n","    :param image:\n","    :param size:\n","    :param noise_scale:\n","    :return:\n","    \"\"\"\n","    img = cv2.resize(image,\n","                        (int(image.shape[1] * size / 100), int(image.shape[0] * size / 100)),\n","                        interpolation=cv2.INTER_CUBIC)\n","    noise = np.random.normal(scale=noise_scale, size=img.shape)\n","    noise = noise.round()\n","    noisy_image = img.astype(np.int16) + noise.astype(np.int16)\n","    clipped_image = noisy_image.clip(0, 255).astype(np.uint8)\n","    return clipped_image\n","\n","\n","image = cv2.imread(\"kiwi.jpg\")\n","cv2.imshow(\"original\", image)\n","cv2.imshow(\"BD\", BD(image, 50))\n","cv2.imshow(\"DN\", DN(image, 50, 30))\n","cv2.waitKey(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mTTiUcmM14aH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYqrqaiEpOWL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}